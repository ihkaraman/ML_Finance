{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings       \n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # verinin okunması\n",
    "    data = pd.read_csv('EurUsd.csv',low_memory=False)\n",
    "    # soru işaretleri olan satırlar veriden silindi.\n",
    "    data = data.replace(\"?\", np.nan)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # none değerlerinin atılamsı\n",
    "    data = drop_none(data, '20_signal')\n",
    "    \n",
    "    # verinin feature larının ayrılması\n",
    "    df_first = data.iloc[:,1:5]\n",
    "    df_middle = data.iloc[:,5:430]\n",
    "\n",
    "    result_signal = data.filter(regex = '_signal').astype('category')\n",
    "    result_numeric = data.filter(regex = '_profitPips')\n",
    "    \n",
    "    return df_first, df_middle, result_signal, result_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_none(data, col_name):\n",
    "    data.drop(index = data[data[col_name]=='NONE'].index, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kategorikleri_dummy_yap(df):\n",
    "    cat_column_names = ['ind_7','ind_11','ind_24','ind_38','ind_54','ind_57','ind_60','ind_63','ind_66','ind_69','ind_72','ind_75',\n",
    "                    'ind_78','ind_81','ind_84','ind_87','ind_89','ind_91','ind_93','ind_95','ind_97','ind_99','ind_101',\n",
    "                    'ind_103','ind_105','ind_107','ind_109', 'ind_111', 'ind_113', 'ind_115','ind_138','ind_141','ind_144',\n",
    "                    'ind_157','ind_159','ind_161','ind_163','ind_165','ind_167','ind_169','ind_171','ind_173','ind_175',\n",
    "                    'ind_177','ind_182','ind_184','ind_187','ind_190','ind_193','ind_196','ind_199','ind_202','ind_205',\n",
    "                    'ind_208','ind_211','ind_213','ind_384','ind_386','ind_388','ind_390']\n",
    "    # categorical kolonların dummy var. oalrak değiştirdik\n",
    "    dms = pd.get_dummies(df[cat_column_names])\n",
    "    dms_none_cols = dms.filter(regex = '_NONE').columns\n",
    "    for i in dms_none_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    dms_red_cols = dms.filter(regex = '_RED').columns\n",
    "    for i in dms_red_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    #datadan categorical olan kolonları çıkarıyoruz ve type nı değiştiriyoruz\n",
    "    df_noncategoric = df.drop(cat_column_names,axis=1).astype(\"float64\")\n",
    "    df_noncategoric = pd.DataFrame(df_noncategoric)\n",
    "    df_all = pd.concat([df_noncategoric, dms], axis=1)\n",
    "    # y değerlerinin alınması\n",
    "    return df_all, df_noncategoric, dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - dropping correlaritions\n",
    "def corr_df(df, corr_val):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_high = [column for column in upper.columns if any(upper[column] > corr_val)]\n",
    "    df.drop(to_high, axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 RandomForest\n",
    "# bütün değişkenlerle yapılan random forest sonucu importance değeri verilen parametreden büyük olan değişkenleri döner\n",
    "def rand_forest(X, y, imp_value):\n",
    "    rf_model = RandomForestClassifier().fit(X, y)\n",
    "    Importance = pd.DataFrame({'Importance':rf_model.feature_importances_*100}, index = X.columns)\n",
    "    imp_values = Importance.sort_values(by = 'Importance', axis = 0, ascending = True)\n",
    "    imp_values = imp_values[imp_values['Importance']>imp_value]\n",
    "    col_names = imp_values.index   \n",
    "    return X[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 - pca\n",
    "def pca_fon(X, threshold):\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(scale(X))\n",
    "    arr = np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n",
    "    num_var = sum((arr < threshold*100)) + 1 \n",
    "    print('pca sonrası değişken sayısı: ',num_var)\n",
    "    X_pcad = pd.DataFrame(X_pca[:,0:num_var], index = X.index)\n",
    "    return X_pcad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - multi lojistik\n",
    "def multi_logit(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "    log = logreg.fit(X_train, y_train)\n",
    "    y_pred = log.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first, df_middle, result_signal, result_numeric = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_signal = result_signal['20_signal']\n",
    "y_numeric = result_numeric['20_profitPips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 den gelen veriler (non correlatedlardan gelenler)\n",
    "df_all, df_noncategoric, dms = kategorikleri_dummy_yap(df_middle)\n",
    "df_noncorr = corr_df(df_noncategoric, 0.50)\n",
    "X1 = pd.concat([df_first, df_noncorr, dms], axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 den gelen veriler. \n",
    "X_raw = pd.concat([df_first,df_all], axis=1) \n",
    "X2 = rand_forest(X_raw, y_signal, 0.1)   \n",
    "X_raw.shape, X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 den gelen veriler.\n",
    "X_raw2 = pd.concat([df_first,df_all], axis=1) \n",
    "X3 = pca_fon(X_raw2, 0.99)\n",
    "X_raw2.shape, X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_1, X_test1_1, y_train1_1, y_test1_1 = splitting(X1, y_signal, 0.20)\n",
    "X_train1_2, X_test1_2, y_train1_2, y_test1_2 = splitting(X1, y_numeric, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_1, X_test2_1, y_train2_1, y_test2_1 = splitting(X2, y_signal, 0.20)\n",
    "X_train2_2, X_test2_2, y_train2_2, y_test2_2 = splitting(X2, y_numeric, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3_1, X_test3_1, y_train3_1, y_test3_1 = splitting(X3, y_signal, 0.20)\n",
    "X_train3_2, X_test3_2, y_train3_2, y_test3_2 = splitting(X3, y_numeric, 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multi lojistik classification')\n",
    "print('X1_1 *********************************')\n",
    "multi_logit(X_train1_1, X_test1_1, y_train1_1, y_test1_1)\n",
    "print('X2_1 *********************************')\n",
    "multi_logit(X_train2_1, X_test2_1, y_train2_1, y_test2_1)\n",
    "print('X3_1 *********************************')\n",
    "multi_logit(X_train3_1, X_test3_1, y_train3_1, y_test3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Dec tree classification')\n",
    "print('X1_1 *********************************')\n",
    "dec_tree(X_train1_1, X_test1_1, y_train1_1, y_test1_1)\n",
    "print('X2_1 *********************************')\n",
    "dec_tree(X_train2_1, X_test2_1, y_train2_1, y_test2_1)\n",
    "print('X3_1 *********************************')\n",
    "dec_tree(X_train3_1, X_test3_1, y_train3_1, y_test3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dec tree for X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dec tree cross validation with X3_1\n",
    "cart = DecisionTreeClassifier()\n",
    "cart_grid = {\"max_depth\":[20,50,100,150,200,300], \"min_samples_split\":[30,100,200,300,400,500,750]}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train3_1, y_train3_1)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 20, min_samples_split=300)\n",
    "cart_tuned = cart.fit(X_train3_1, y_train3_1)\n",
    "ypred_train = cart_tuned.predict(X_train3_1)\n",
    "y_pred3_1 = cart_tuned.predict(X_test3_1)\n",
    "print('accuracy score for train : ',accuracy_score(y_test3_1, y_pred3_1))\n",
    "print('class. report for train: ')\n",
    "print(classification_report(y_train3_1, ypred_train))\n",
    "print('class. report for test: ')\n",
    "print(classification_report(y_test3_1, y_pred3_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dec tree for X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec tree cross validation with X2_1\n",
    "cart = DecisionTreeClassifier()\n",
    "cart_grid = {\"max_depth\":[20,30,50,75,100,150,200,250,300], \"min_samples_split\":[20,30,50,75,100,120,150,200,300]}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train2_1, y_train2_1)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 50, min_samples_split=100)\n",
    "cart_tuned = cart.fit(X_train2_1, y_train2_1)\n",
    "ypred_train = cart_tuned.predict(X_train2_1)\n",
    "y_pred2_1 = cart_tuned.predict(X_test2_1)\n",
    "print('accuracy score for train : ',accuracy_score(y_test2_1, y_pred2_1))\n",
    "print('class. report for train: ')\n",
    "print(classification_report(y_train2_1, ypred_train))\n",
    "print('class. report for test: ')\n",
    "print(classification_report(y_test2_1, y_pred2_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dec tree for X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec tree cross validation with X3_1\n",
    "cart = DecisionTreeClassifier()\n",
    "cart_grid = {\"max_depth\":[20,30,50,75,100,150,200,250,300], \"min_samples_split\":[20,30,50,75,100,120,150,200,300]}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train1_1, y_train1_1)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 30, min_samples_split=100)\n",
    "cart_tuned = cart.fit(X_train1_1, y_train1_1)\n",
    "ypred_train = cart_tuned.predict(X_train1_1)\n",
    "y_pred1_1 = cart_tuned.predict(X_test1_1)\n",
    "print('accuracy score for train : ',accuracy_score(y_test1_1, y_pred1_1))\n",
    "print('class. report for train: ')\n",
    "print(classification_report(y_train1_1, ypred_train))\n",
    "print('class. report for test: ')\n",
    "print(classification_report(y_test1_1, y_pred1_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec tree cross validation with X3_1\n",
    "cart = DecisionTreeClassifier()\n",
    "cart_grid = {\"max_depth\":[2,5,8,10,20,50,100,200], \"min_samples_split\":[2,5,10,20,50,100,300]}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train1_1, y_train1_1)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 50, min_samples_split=50)\n",
    "cart_tuned = cart.fit(X_train1_1, y_train1_1)\n",
    "ypred_train = cart_tuned.predict(X_train1_1)\n",
    "y_pred1_1 = cart_tuned.predict(X_test1_1)\n",
    "print('accuracy score for train : ',accuracy_score(y_test1_1, y_pred1_1))\n",
    "print('class. report for train: ')\n",
    "print(classification_report(y_train1_1, ypred_train))\n",
    "print('class. report for test: ')\n",
    "print(classification_report(y_test1_1, y_pred1_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr1 = DecisionTreeRegressor()\n",
    "regr1.fit(X_train1_2, y_train1_2)\n",
    "y_pred_train = regr1.predict(X_train1_2)\n",
    "y_pred_test = regr1.predict(X_test1_2)\n",
    "print('train score: ',regr1.score(X_train1_2, y_train1_2, sample_weight=None))\n",
    "print('test score: ',regr1.score(X_test1_2, y_test1_2, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_train = y_train1_2 - y_pred_train\n",
    "diff_test = y_test1_2 - y_pred_test\n",
    "diff_train.plot(figsize=(100,10))\n",
    "diff_test.plot(figsize=(100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Squared Error - train:', metrics.mean_squared_error(y_train1_2, y_pred_train))\n",
    "print('Mean Squared Error - test:', metrics.mean_squared_error(y_test1_2, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(250,8))\n",
    "y_test2, y_pred\n",
    "\n",
    "x = y_test2.index\n",
    "y1 =y_test2\n",
    "y2 =y_pred\n",
    "\n",
    "plt.scatter(x, y1, c=\"g\", alpha=0.5,\n",
    "            label=\"test\")\n",
    "plt.scatter(x, y2, c=\"b\", alpha=0.5,\n",
    "            label=\"pred\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(250,8))\n",
    "y_test2, y_pred\n",
    "\n",
    "x = y_test2.index\n",
    "\n",
    "plt.scatter(x, diff, c=\"g\", alpha=0.5,\n",
    "            label=\"test\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=1000, random_state=np.random.RandomState(1))\n",
    "regr_2.fit(X_train2, y_train2)\n",
    "y_pred2 = regr_2.predict(X_test2)\n",
    "print('train score: ',regr_2.score(X_train2, y_train2, sample_weight=None))\n",
    "print('test score: ',regr_2.score(X_test2, y_test2, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_test2\n",
    "diff = y_test2 - y_pred\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [100,200,500],\n",
    "              'min_samples_split': [100,200,300]}\n",
    "\n",
    "clf = GridSearchCV(tree.DecisionTreeRegressor(), \n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_squared_error',\n",
    "                   cv=5 , n_jobs=-1, verbose=2)\n",
    "%time _ = clf.fit(X_train2, y_train2)\n",
    "print('En iyi parametreler : ' + str(clf .best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_tuned = DecisionTreeRegressor(max_depth=100,min_samples_split=50)\n",
    "regr_tuned.fit(X_train2, y_train2)\n",
    "y_pred_tuned = regr_tuned.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train score: ',regr_tuned.score(X_train2, y_train2, sample_weight=None))\n",
    "print('test score: ',regr_tuned.score(X_test2, y_test2, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=200,min_samples_split=100), n_estimators=1000,learning_rate=0.1, random_state=np.random.RandomState(1))\n",
    "regr_2.fit(X_train2, y_train2)\n",
    "y_pred2 = regr_2.predict(X_test2)\n",
    "print('train score: ',regr_2.score(X_train2, y_train2, sample_weight=None))\n",
    "print('test score: ',regr_2.score(X_test2, y_test2, sample_weight=None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [100,200,300,500]:\n",
    "    print('//////////////')\n",
    "    print('max_depth: ', i)\n",
    "    for j in [100,200,300]:\n",
    "        print('*****************')\n",
    "        print('min_samples_split: ', j)\n",
    "        for k in [200,300,500]:\n",
    "            print('-------------')\n",
    "            print('n_estimators: ', k)\n",
    "            for l in [0.001,0.005,0.05]:\n",
    "                print('++++++++++++++++')\n",
    "                print('learning_rate: ', l)\n",
    "                regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=i,min_samples_split=j), n_estimators=k,learning_rate=l, random_state=np.random.RandomState(1))\n",
    "                regr_2.fit(X_train2, y_train2)\n",
    "                y_pred2 = regr_2.predict(X_test2)\n",
    "                print('train score: ',regr_2.score(X_train2, y_train2, sample_weight=None))\n",
    "                print('test score: ',regr_2.score(X_test2, y_test2, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "# X_train = scaler.transform(X_train1)\n",
    "# X_test = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train1, y_train1)\n",
    "y_pred = classifier.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test1, y_pred))\n",
    "print(classification_report(y_test1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly', degree=8)\n",
    "svclassifier.fit(X_train1, y_train1)\n",
    "y_pred = svclassifier.predict(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test1, y_pred))\n",
    "print(classification_report(y_test1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
